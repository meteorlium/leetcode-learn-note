# PyTorch view() vs reshape() è¯¦è§£

## æ ¸å¿ƒè¦ç‚¹é€Ÿè§ˆ

**æœ€å…³é”®çš„åŒºåˆ«ï¼š**
- **view()**: è¦æ±‚å¼ é‡è¿ç»­ï¼Œ0æˆæœ¬ï¼Œæ€»æ˜¯å…±äº«å†…å­˜
- **reshape()**: è‡ªåŠ¨å¤„ç†è¿ç»­æ€§ï¼Œæ™ºèƒ½é€‰æ‹©ï¼Œå°½é‡å…±äº«å†…å­˜

**é€‰æ‹©åŸåˆ™ï¼š**
- ğŸš€ **æ€§èƒ½æ•æ„Ÿåœºæ™¯** â†’ ç”¨ `view()`ï¼ˆç¡®ä¿è¾“å…¥è¿ç»­ï¼‰
- ğŸ›¡ï¸ **é€šç”¨/å®‰å…¨ä»£ç ** â†’ ç”¨ `reshape()`ï¼ˆè‡ªåŠ¨å¤„ç†ä¸€åˆ‡ï¼‰
- ğŸ“š **æ–°æ‰‹å­¦ä¹ ** â†’ ç”¨ `reshape()`ï¼ˆä¸ä¼šå‡ºé”™ï¼‰

**æœ€å¸¸è§é”™è¯¯ï¼š**
```python
x = torch.randn(2, 3, 4)
y = x.transpose(0, 1).view(-1)  # âŒ æŠ¥é”™ï¼éè¿ç»­å¼ é‡
z = x.transpose(0, 1).reshape(-1) # âœ… æ­£ç¡®ï¼è‡ªåŠ¨å¤„ç†
```

---

## æ¦‚è¿°
`view()` å’Œ `reshape()` æ˜¯ PyTorch ä¸­ä¸¤ä¸ªå¸¸ç”¨çš„å¼ é‡å½¢çŠ¶å˜æ¢æ–¹æ³•ï¼Œè™½ç„¶åŠŸèƒ½ç›¸ä¼¼ä½†æœ‰é‡è¦åŒºåˆ«ã€‚è¿™æ˜¯é¢è¯•ä¸­çš„é«˜é¢‘è€ƒç‚¹ã€‚

## è®¾è®¡åŠ¨æœºç®€è¿°

### view() - "é›¶æˆæœ¬è§†å›¾"
- **æ ¸å¿ƒç†å¿µ**: åªæ”¹å˜"è§‚å¯Ÿæ–¹å¼"ï¼Œä¸ç§»åŠ¨æ•°æ®
- **å†…å­˜åŸç†**: å¼ é‡æ˜¯ä¸€ç»´æ•°ç»„ + å½¢çŠ¶å…ƒæ•°æ®ï¼ˆshape, strideï¼‰
- **æ€§èƒ½**: O(1)æ—¶é—´å¤æ‚åº¦ï¼Œæ— å†…å­˜å¼€é”€

```python
# viewåªæ”¹å˜å…ƒæ•°æ®ï¼Œdata_pträ¸å˜
data = [1,2,3,4,5,6]  # ç‰©ç†å­˜å‚¨ä¸å˜
tensor_2x3 â†’ [[1,2,3], [4,5,6]]  # åªæ˜¯è§£é‡Šæ–¹å¼æ”¹å˜
```

### reshape() - "æ™ºèƒ½åŒ…è£…å™¨" 
- **å†å²**: PyTorch 0.4 (2018) å¼•å…¥ï¼Œè§£å†³æ˜“ç”¨æ€§é—®é¢˜
- **è®¾è®¡å“²å­¦**: ç”¨æˆ·ä¸åº”å…³å¿ƒå†…å­˜å¸ƒå±€ç»†èŠ‚ï¼ˆå­¦ä¹ NumPyï¼‰
- **å®ç°ç­–ç•¥**: `è¿ç»­æ—¶ç”¨viewï¼Œéè¿ç»­æ—¶å…ˆcontiguous()`

```python
# reshapeçš„æ™ºèƒ½é€‰æ‹©
def reshape(tensor, shape):
    if tensor.is_contiguous():
        return tensor.view(shape)      # å¿«é€Ÿè·¯å¾„
    else:
        return tensor.contiguous().view(shape)  # å®‰å…¨è·¯å¾„
```

## å†…å­˜å¸ƒå±€åŸç†

### è¿ç»­æ€§æ ¸å¿ƒæ¦‚å¿µ
```python
# strideï¼ˆæ­¥é•¿ï¼‰å†³å®šäº†å†…å­˜è®¿é—®æ¨¡å¼
x = torch.arange(24).reshape(2, 3, 4)
print(x.stride())  # (12, 4, 1)
# è®¿é—®x[i,j,k] = å†…å­˜åç§» i*12 + j*4 + k*1

# è¿ç»­æ€§è§„åˆ™ï¼šstride[i] = stride[i+1] * shape[i+1]
# [12, 4, 1] = [4*3, 1*4, 1] âœ… è¿ç»­

# transposeç ´åè¿ç»­æ€§
x_t = x.transpose(0, 1)
print(x_t.stride())  # (4, 12, 1) âŒ éè¿ç»­
```

### view() çš„çº¦æŸæ¡ä»¶
1. **å…ƒç´ æ€»æ•°ç›¸ç­‰**: `np.prod(old_shape) == np.prod(new_shape)`
2. **å¿…é¡»è¿ç»­**: `tensor.is_contiguous() == True`
3. **strideå…¼å®¹**: æ–°å½¢çŠ¶ä¸åŸæœ‰strideå…¼å®¹


## æ ¸å¿ƒåŒºåˆ«å¯¹æ¯”

| ç‰¹æ€§ | view() | reshape() |
|------|--------|-----------|
| **è¿ç»­æ€§è¦æ±‚** | å¿…é¡»è¿ç»­ | è‡ªåŠ¨å¤„ç† |
| **å†…å­˜å…±äº«** | æ€»æ˜¯å…±äº« | å°½é‡å…±äº« |
| **æ€§èƒ½** | æœ€å¿« | ç¨æ…¢ |
| **å®‰å…¨æ€§** | ä¸¥æ ¼æ£€æŸ¥ | æ›´å®½æ¾ |
| **å¼•å…¥ç‰ˆæœ¬** | æ—©æœŸç‰ˆæœ¬ | PyTorch 0.4+ |

## 1. è¿ç»­æ€§è¦æ±‚

### view() - ä¸¥æ ¼è¦æ±‚è¿ç»­æ€§
```python
import torch

# è¿ç»­å¼ é‡ - viewæ­£å¸¸å·¥ä½œ
x = torch.randn(2, 3, 4)
print(f"è¿ç»­æ€§: {x.is_contiguous()}")  # True
y = x.view(6, 4)  # âœ… æˆåŠŸ

# éè¿ç»­å¼ é‡ - viewå¤±è´¥
x_t = x.transpose(0, 1)  # è½¬ç½®åéè¿ç»­
print(f"è½¬ç½®åè¿ç»­æ€§: {x_t.is_contiguous()}")  # False
try:
    y = x_t.view(6, 4)  # âŒ æŠ¥é”™
except RuntimeError as e:
    print(f"viewé”™è¯¯: {e}")
    # RuntimeError: view size is not compatible with input tensor's size and stride
```

### reshape() - è‡ªåŠ¨å¤„ç†éè¿ç»­æ€§
```python
# reshapeè‡ªåŠ¨å¤„ç†éè¿ç»­æƒ…å†µ
x = torch.randn(2, 3, 4)
x_t = x.transpose(0, 1)  # éè¿ç»­

y = x_t.reshape(6, 4)  # âœ… æˆåŠŸï¼Œè‡ªåŠ¨è°ƒç”¨contiguous()
print(f"reshapeæˆåŠŸ: {y.shape}")
```

## 2. å†…å­˜å…±äº«è¡Œä¸º

### view() - æ€»æ˜¯å…±äº«å†…å­˜
```python
x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)
x_view = x.view(3, 2)

# ä¿®æ”¹åŸå¼ é‡
x[0, 0] = 999
print(x_view)  # ç¬¬ä¸€ä¸ªå…ƒç´ ä¹Ÿå˜æˆ999ï¼Œè¯´æ˜å…±äº«å†…å­˜

# æ£€æŸ¥å†…å­˜åœ°å€
print(f"å…±äº«å†…å­˜: {x.data_ptr() == x_view.data_ptr()}")  # True
```

### reshape() - å°½é‡å…±äº«ï¼Œå¿…è¦æ—¶å¤åˆ¶
```python
# è¿ç»­å¼ é‡ - reshapeå…±äº«å†…å­˜
x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)
x_reshape = x.reshape(3, 2)
print(f"è¿ç»­æ—¶å…±äº«å†…å­˜: {x.data_ptr() == x_reshape.data_ptr()}")  # True

# éè¿ç»­å¼ é‡ - reshapeå¯èƒ½å¤åˆ¶
x_t = x.transpose(0, 1)
x_reshape = x_t.reshape(3, 2)
print(f"éè¿ç»­æ—¶å…±äº«å†…å­˜: {x_t.data_ptr() == x_reshape.data_ptr()}")  # False
```

## å¸¸è§é”™è¯¯é€ŸæŸ¥

```python
# âŒ éè¿ç»­å¼ é‡ç”¨view
x_t = x.transpose(0, 1)
y = x_t.view(-1)  # æŠ¥é”™

# âœ… è§£å†³æ–¹æ¡ˆ
y = x_t.reshape(-1)              # æ–¹æ¡ˆ1: ç”¨reshape
y = x_t.contiguous().view(-1)    # æ–¹æ¡ˆ2: å…ˆcontiguous

# âŒ å…ƒç´ æ•°é‡ä¸åŒ¹é…
x = torch.randn(2, 3, 4)  # 24ä¸ªå…ƒç´   
y = x.view(5, 5)          # 25ä¸ªå…ƒç´ ï¼ŒæŠ¥é”™

# âœ… æ­£ç¡®å†™æ³•
y = x.view(-1, 4)  # è‡ªåŠ¨è®¡ç®—ç¬¬ä¸€ç»´ï¼š24/4=6
```


## é¢è¯•å¿…çŸ¥é—®é¢˜

**Q1: ä¸»è¦åŒºåˆ«ï¼Ÿ**
- è¿ç»­æ€§ï¼šviewå¿…é¡»è¿ç»­ï¼Œreshapeè‡ªåŠ¨å¤„ç†
- æ€§èƒ½ï¼šviewæ›´å¿«ï¼Œreshapeç¨æ…¢ä½†å®‰å…¨
- å†…å­˜ï¼šviewæ€»å…±äº«ï¼Œreshapeå°½é‡å…±äº«

**Q2: ä½•æ—¶éè¿ç»­ï¼Ÿ**
```python
x.transpose(0, 1)    # è½¬ç½®
x[:, ::2, :]        # åˆ‡ç‰‡
x.narrow(1, 0, 2)   # çª„å£
```

**Q3: å¦‚ä½•ä¿®å¤ï¼Ÿ**
```python
tensor.is_contiguous()           # æ£€æŸ¥
tensor.contiguous().view(...)    # ä¿®å¤+view
tensor.reshape(...)              # ç›´æ¥reshape
```

## æœ€ä½³å®è·µ

```python
# æ€§èƒ½æ•æ„Ÿåœºæ™¯ï¼šä½¿ç”¨ view()
x.view(batch_size, -1)  # ç¡®ä¿è¾“å…¥è¿ç»­

# é€šç”¨/å®‰å…¨ä»£ç ï¼šä½¿ç”¨ reshape()
x.reshape(batch_size, -1)  # è‡ªåŠ¨å¤„ç†ä¸€åˆ‡

# å®‰å…¨çš„ view æ“ä½œ
if not x.is_contiguous():
    x = x.contiguous()
y = x.view(new_shape)
```

## æ€»ç»“

**é€‰æ‹©åŸåˆ™**ï¼š
- ğŸš€ **æ€§èƒ½ä¼˜å…ˆ** â†’ `view()` ï¼ˆç¡®ä¿è¾“å…¥è¿ç»­ï¼‰
- ğŸ›¡ï¸ **å®‰å…¨ä¼˜å…ˆ** â†’ `reshape()` ï¼ˆè‡ªåŠ¨å¤„ç†ä¸€åˆ‡ï¼‰
- ğŸ“š **æ–°æ‰‹å­¦ä¹ ** â†’ `reshape()` ï¼ˆä¸ä¼šå‡ºé”™ï¼‰

**é¢è¯•è¦ç‚¹**ï¼š
1. è¿ç»­æ€§æ¦‚å¿µå’Œæ£€æŸ¥æ–¹æ³•
2. æ€§èƒ½å’Œå†…å­˜è¡Œä¸ºå·®å¼‚
3. å®é™…åœºæ™¯çš„é€‰æ‹©ç­–ç•¥